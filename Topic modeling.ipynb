{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "part1 = r'@[A-Za-z0-9]+'\n",
    "part2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_part = r'|'.join((part1, part2))\n",
    "\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'https\\S+', '', text)\n",
    "    \n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    soup_text = soup.get_text()\n",
    "    stripped = re.sub(combined_part, '', soup_text)\n",
    "    \n",
    "    try:\n",
    "        clean = stripped.replace(u\"ï¿½\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    \n",
    "    clean = re.sub(\"'\", \"\", clean)\n",
    "    # remove all non letter and irrelevant punctuation\n",
    "    clean = re.sub( r'([?!])', r' \\1 ', clean)\n",
    "    clean = re.sub(\"[^a-zA-Z?!]\", \" \", clean)\n",
    "    \n",
    "    # all letters to lower case\n",
    "    clean = clean.lower()\n",
    "    \n",
    "    #remove all extra spaces\n",
    "    tok = WordPunctTokenizer()\n",
    "    words = tok.tokenize(clean)\n",
    "    \n",
    "    #join list into a sentence\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"hijaako.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philippines Hashtag Battle: #HijaAko Vs #AmaAko - The ASEAN Post https://theaseanpost.com/article/philippines-hashtag-battle-hijaako-vs-amaako?utm_source=dlvr.it&utm_medium=twitter …\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'philippines hashtag battle hijaako vs amaako the asean post'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['tweet'][0])\n",
    "text_cleaner(df['tweet'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet\"]=df[\"tweet\"].apply(lambda x: text_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=lemmatization(df.tweet.values.tolist(), allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(df.tweet.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=1,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             max_features=5000,             # max number of uniq words\n",
    "                            )\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(df[\"tweet\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsicity:  0.23795474200057654 %\n"
     ]
    }
   ],
   "source": [
    "# Materialize the sparse data\n",
    "data_dense = data_vectorized.todense()\n",
    "\n",
    "# Compute Sparsicity = Percentage of Non-Zero cells\n",
    "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "                          evaluate_every=-1, learning_decay=0.7,\n",
      "                          learning_method='online', learning_offset=10.0,\n",
      "                          max_doc_update_iter=100, max_iter=15,\n",
      "                          mean_change_tol=0.001, n_components=5, n_jobs=-1,\n",
      "                          perp_tol=0.1, random_state=100, topic_word_prior=None,\n",
      "                          total_samples=1000000.0, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation( \n",
    "                                     n_components=5,# Number of topics\n",
    "                                      max_iter=15,               # Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          # Random state\n",
    "                                      batch_size=128,            # n docs in each learning iter\n",
    "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -1214423.596052154\n",
      "Perplexity:  879.2206036724059\n",
      "{'batch_size': 128, 'doc_topic_prior': None, 'evaluate_every': -1, 'learning_decay': 0.7, 'learning_method': 'online', 'learning_offset': 10.0, 'max_doc_update_iter': 100, 'max_iter': 15, 'mean_change_tol': 0.001, 'n_components': 5, 'n_jobs': -1, 'perp_tol': 0.1, 'random_state': 100, 'topic_word_prior': None, 'total_samples': 1000000.0, 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "\n",
    "# See model parameters\n",
    "print(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LatentDirichletAllocation(batch_size=128,\n",
       "                                                 doc_topic_prior=None,\n",
       "                                                 evaluate_every=-1,\n",
       "                                                 learning_decay=0.7,\n",
       "                                                 learning_method='online',\n",
       "                                                 learning_offset=10.0,\n",
       "                                                 max_doc_update_iter=100,\n",
       "                                                 max_iter=10,\n",
       "                                                 mean_change_tol=0.001,\n",
       "                                                 n_components=10, n_jobs=-1,\n",
       "                                                 perp_tol=0.1, random_state=100,\n",
       "                                                 topic_word_prior=None,\n",
       "                                                 total_samples=1000000.0,\n",
       "                                                 verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_decay': [0.7], 'n_components': [3, 4, 5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [3,4,5], 'learning_decay': [.7]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation( n_jobs = -1,batch_size=128, evaluate_every = -1,max_iter=10,learning_method='online', random_state=100)\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 3}\n",
      "Best Log Likelihood Score:  -258165.4714509204\n",
      "Model Perplexity:  786.6139091762855\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, vectorizer, mds='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2987629542070888407553297465\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2987629542070888407553297465_data = {\"mdsDat\": {\"x\": [150.22215270996094, 51.16336441040039, -73.1445541381836, -66.4101333618164, 54.41732406616211], \"y\": [-72.2695541381836, -159.968017578125, 21.523815155029297, -110.60643768310547, 12.44344425201416], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [42.64184905254801, 21.17490447320179, 13.397385353495158, 12.89147547315327, 9.89438564760178]}, \"tinfo\": {\"Term\": [\"hijaako\", \"twitter\", \"ang\", \"pic\", \"com\", \"ako\", \"mga\", \"dress\", \"wearing\", \"yung\", \"old\", \"hindi\", \"way\", \"lang\", \"kung\", \"stop\", \"niyo\", \"tulfo\", \"ben\", \"women\", \"walang\", \"wear\", \"men\", \"kayo\", \"kasi\", \"manyak\", \"babae\", \"years\", \"stopvictimblaming\", \"para\", \"wearing\", \"stop\", \"wear\", \"clothes\", \"people\", \"know\", \"harassed\", \"fault\", \"sexually\", \"want\", \"did\", \"touched\", \"long\", \"feel\", \"story\", \"speak\", \"say\", \"stories\", \"let\", \"right\", \"exists\", \"hand\", \"catcalled\", \"groped\", \"body\", \"assault\", \"tell\", \"telling\", \"youre\", \"thinking\", \"times\", \"women\", \"dont\", \"victims\", \"happened\", \"sexual\", \"rapists\", \"blaming\", \"just\", \"got\", \"victim\", \"school\", \"man\", \"raped\", \"time\", \"uniform\", \"shirt\", \"guy\", \"men\", \"girls\", \"rape\", \"like\", \"hijaako\", \"harassment\", \"pants\", \"think\", \"ako\", \"manyak\", \"kasi\", \"wala\", \"kaya\", \"nila\", \"suot\", \"kasalanan\", \"sila\", \"niya\", \"naka\", \"nung\", \"yun\", \"kami\", \"siya\", \"alam\", \"akong\", \"bakit\", \"nya\", \"tapos\", \"kong\", \"sobrang\", \"yon\", \"bastos\", \"sakin\", \"sya\", \"natin\", \"iba\", \"habang\", \"nun\", \"walang\", \"yung\", \"anong\", \"kahit\", \"yan\", \"pero\", \"kung\", \"lang\", \"naman\", \"lalaki\", \"talaga\", \"hindi\", \"mga\", \"dahil\", \"ang\", \"rapist\", \"hijaako\", \"pag\", \"babae\", \"twitter\", \"pic\", \"com\", \"teach\", \"trash\", \"asking\", \"endrapeculture\", \"world\", \"proud\", \"lets\", \"decent\", \"doing\", \"doesn\", \"try\", \"normal\", \"rights\", \"finally\", \"vhong\", \"ill\", \"hijoako\", \"wears\", \"words\", \"lives\", \"god\", \"literally\", \"leave\", \"beasts\", \"new\", \"stan\", \"navarro\", \"ben\", \"tulfo\", \"hijaako\", \"stopvictimblaming\", \"beast\", \"metoo\", \"stopvictimshaming\", \"men\", \"rape\", \"consent\", \"movement\", \"stand\", \"rapist\", \"women\", \"support\", \"niyo\", \"nyo\", \"pananamit\", \"nasa\", \"biktima\", \"rhymeswithwrong\", \"nang\", \"frankie\", \"sana\", \"pang\", \"taong\", \"ito\", \"yrs\", \"bahay\", \"mong\", \"kayong\", \"problema\", \"yang\", \"pangilinan\", \"kababaihan\", \"kayo\", \"ladies\", \"tweet\", \"kay\", \"iisip\", \"toxic\", \"niyong\", \"huwag\", \"ilang\", \"ulit\", \"para\", \"ang\", \"mga\", \"babae\", \"tayo\", \"lahat\", \"utak\", \"hindi\", \"isang\", \"hijaako\", \"rape\", \"wag\", \"lang\", \"kung\", \"mag\", \"victim\", \"dress\", \"old\", \"sexy\", \"hija\", \"tried\", \"sex\", \"girl\", \"house\", \"short\", \"stoprapingwomen\", \"molested\", \"instead\", \"legs\", \"yall\", \"making\", \"dressed\", \"room\", \"self\", \"maybe\", \"cases\", \"theres\", \"touching\", \"trending\", \"protectourstudents\", \"darssthsdobetter\", \"offenders\", \"stupid\", \"uncle\", \"came\", \"lol\", \"person\", \"way\", \"years\", \"yes\", \"friend\", \"hijaako\", \"tshirt\", \"rapist\", \"mean\"], \"Freq\": [15224.0, 1594.0, 2208.0, 1534.0, 1523.0, 1629.0, 1794.0, 830.0, 1723.0, 1032.0, 593.0, 1043.0, 660.0, 920.0, 900.0, 1148.0, 466.0, 600.0, 538.0, 1402.0, 532.0, 921.0, 1062.0, 362.0, 468.0, 466.0, 573.0, 458.0, 586.0, 399.0, 1722.2520793102224, 1147.9210189097162, 920.8296807608857, 759.5987058061596, 654.7083770872889, 540.8871404368011, 397.4494039675785, 379.62367675871667, 340.53213752513034, 379.55016904155497, 270.7961229196388, 246.50973178849645, 239.8112115687077, 234.97019301220806, 231.61849531505322, 227.2871786335181, 220.7992667738691, 220.7572850847112, 212.19360946905044, 211.48917905108755, 188.36209696766085, 180.9618592157272, 180.19007973509804, 176.72814796028044, 171.73027372480203, 183.81811598673593, 505.80353576871806, 181.44504885471193, 153.67988747648798, 151.70837633611112, 201.63677871490137, 1321.1561645798645, 652.6570861087749, 448.011205939374, 328.7258123489424, 682.8265509676672, 633.9530866211035, 795.2598527074971, 835.8307871898928, 333.8868693838243, 842.8678451398661, 694.7699755948912, 652.2605823446374, 422.44716253910417, 555.5833041068628, 681.7294110490709, 447.54116840931164, 296.7079409802887, 817.789104744527, 314.84381787368665, 1568.9312598260908, 471.2698233059841, 4440.557325325399, 346.0863184295787, 361.55946954540053, 349.41275619529324, 1628.869032534312, 465.7326833891393, 467.4255683298588, 426.3985334573821, 359.1724195533942, 321.2111353355504, 401.27888653420706, 287.1460724703473, 286.9334401898011, 286.7662737253736, 251.97779648287624, 248.53713770182193, 231.25592552664193, 264.6268814464943, 203.44689882869525, 196.21383900310252, 192.20654882529436, 289.1038407935612, 179.63519611171745, 178.5696319553212, 153.236758980746, 150.9068794584564, 143.36066699408616, 124.47735024750511, 116.81184128255573, 111.84241952129707, 112.38825371310804, 110.57385888460023, 105.01240261907452, 102.87689489071097, 524.920538404447, 995.4887816042241, 166.1428910766076, 404.8247182849387, 410.7839165448272, 493.8994198911117, 760.7648652898736, 752.0198941023389, 337.304847748714, 231.92468311684902, 302.83694081030495, 646.0573781390261, 752.6816194126505, 278.45011411784526, 709.6096902002566, 421.3811521533497, 1678.5146396850448, 253.86326869552852, 279.2228324807867, 1593.2171928657613, 1533.802224187176, 1523.1262305213497, 279.46400069042215, 241.73430771772848, 193.0278304081371, 148.2632407021498, 121.38397208204351, 120.23335349721737, 100.23733818541447, 102.35940434441129, 90.22390839288641, 75.32702481647378, 70.72688620479543, 70.60889026762274, 62.57480279251516, 62.05469950959841, 61.46746923767645, 59.80495368944033, 59.23179297457212, 57.733865457256286, 55.83312925829571, 55.23470094041684, 52.319607347681206, 52.046043652505446, 49.650685168496416, 47.30036610879647, 46.327858701480146, 45.05890250088627, 43.50331271670154, 448.49767552913653, 493.77093954881116, 6988.32482663003, 397.11549875823846, 136.56739427015518, 157.68114884036515, 78.07137838117053, 243.88032955351093, 367.8343829465005, 126.03038736982575, 69.61297448683295, 71.69839409348279, 86.85949546438678, 80.97057007531576, 64.39717390278703, 465.64149878412894, 303.34260916917395, 271.0787368696918, 271.54261505305846, 156.05502777270252, 151.06738370421428, 150.58862307117047, 126.19978445844718, 124.13793642675454, 118.26515977800624, 107.48402899099187, 107.34321803228897, 117.39182398640821, 97.75139956857197, 93.07858313635626, 91.72154652712354, 90.18483531715707, 89.11237032485789, 88.64303747963687, 86.54998094512617, 358.7734825169918, 88.14315390263944, 81.13321559073682, 76.4812679351921, 73.70215321697867, 75.04758728306284, 72.31667442014715, 70.12967714828571, 68.37294436078706, 66.94483443366474, 338.74151653196395, 1498.6200342563898, 1041.21046169814, 293.4774612525867, 99.19630616705014, 138.8645404222807, 180.41589051039855, 397.0072702323751, 136.37046833695206, 1166.1141922260276, 455.25388804663186, 132.81628291353502, 167.61330963619605, 139.19911930326083, 104.71673842597565, 105.82098999392379, 830.1247069489091, 592.8799596231304, 218.7427233061884, 214.5115757888287, 181.84671352840527, 163.0950277453616, 143.7045303117869, 130.67964690928474, 131.7567866000427, 125.89106824576723, 124.34180851827972, 120.63790518141322, 117.41151151549582, 111.4400521451977, 100.04606948307614, 94.37250190372492, 93.45372543084116, 84.3631828993856, 83.11305329679693, 82.73420205213992, 81.0975239303764, 80.58644266847895, 79.00359698825339, 72.03337737090678, 71.35795508503688, 70.76561079820452, 67.19851792679742, 65.96994727453267, 64.68704307673042, 64.07612632395107, 157.68466810196094, 386.5241882857294, 247.37449776820404, 131.05123835856568, 124.04689165711198, 951.3249580979489, 97.90399181576468, 163.01975908074323, 85.26050295656174], \"Total\": [15224.0, 1594.0, 2208.0, 1534.0, 1523.0, 1629.0, 1794.0, 830.0, 1723.0, 1032.0, 593.0, 1043.0, 660.0, 920.0, 900.0, 1148.0, 466.0, 600.0, 538.0, 1402.0, 532.0, 921.0, 1062.0, 362.0, 468.0, 466.0, 573.0, 458.0, 586.0, 399.0, 1723.0655757662519, 1148.7961638678044, 921.6424034871624, 760.4119796394502, 655.5227958036833, 541.7021359359583, 398.2605409668179, 380.43350350799545, 341.34476008967465, 380.49183611156667, 271.61111440995467, 247.32120155618907, 240.62841811310008, 235.78565262876273, 232.435930238742, 228.10206177048178, 221.6202211105744, 221.57912738956662, 213.01191723146002, 212.30702154994492, 189.17571881694315, 181.7728125980824, 180.99977430628311, 177.53753930928474, 172.54610271852823, 184.71220743116868, 508.36084444060265, 182.37159848928746, 154.49480658157455, 152.5231056316879, 202.810167529857, 1402.737969496462, 686.2104228551746, 464.1983605946245, 338.4324294017774, 726.0221343351557, 676.1371094511043, 862.1723987095451, 916.2932895543274, 351.8291553083398, 975.9163562577487, 793.8673552886617, 746.2002713720061, 460.56250948572875, 630.0167050786765, 810.6244657027205, 497.3384808167712, 310.4299307938804, 1062.2817860128353, 334.1019560603108, 2559.8720475517366, 568.4953913949957, 15224.83594196445, 382.3449451354627, 432.62260304489325, 397.78099531924227, 1629.6747945889065, 466.53677114888416, 468.2330100188469, 427.20223567441786, 359.9764248968937, 322.0148787250958, 402.2988225424995, 287.94841523632215, 287.73597468182663, 287.56853246383685, 252.77699528016637, 249.3362596668853, 232.05710136168034, 265.56679656977064, 204.2530951494398, 197.01823619037418, 193.00646475200443, 290.3692726823671, 180.43554655706205, 179.37576400482615, 154.0377328259274, 151.7114879822331, 144.16289656713897, 125.28505595929276, 117.61206918047044, 112.64470861471771, 113.19771436938501, 111.37754929704005, 105.81348186404004, 103.67715361928481, 532.3316207046691, 1032.813290951319, 168.2980508308408, 430.69828097343475, 443.8578550081803, 556.0447738441637, 900.5570173327318, 920.2297058267644, 374.05630093393876, 253.9255820923907, 355.9658349090441, 1043.6574111854416, 1794.4854439900175, 373.9899485331765, 2208.8228427210483, 880.619834775665, 15224.83594196445, 336.8021406670519, 573.2924965623529, 1594.0132670007147, 1534.5976381835596, 1523.9215414772355, 280.2679579375013, 242.54012366457414, 193.83995202154688, 149.06182342627937, 122.1915931752491, 121.04024423766815, 101.03966741579262, 103.18758797013291, 91.05117322071123, 76.14177724212233, 71.54460018449623, 71.4383026946645, 63.38263405414298, 62.859867714664645, 62.2695854578255, 60.614775898265265, 60.04720204586187, 58.54436603409284, 56.64294780182278, 56.043308486166175, 53.13041966279901, 52.86076353178402, 50.467033000337125, 48.104672581848945, 47.134634301733605, 45.8569310554451, 44.302752492745164, 538.0179544087297, 600.5013387677624, 15224.83594196445, 586.8896292120988, 171.08779424164945, 230.4825060100395, 100.28821998024264, 1062.2817860128353, 2559.8720475517366, 308.3570639053134, 137.1641388993976, 173.61554209729294, 880.619834775665, 1402.737969496462, 117.72834637534773, 466.4339415297183, 304.13581113769754, 271.8735609083999, 272.3509536025491, 156.8487715375499, 151.866926421657, 151.38738437755234, 126.99756739497013, 124.93233711216402, 119.06549689941002, 108.27703273897546, 108.13699865712022, 118.27260479212154, 98.56634596501726, 93.87378343330343, 92.51505031668552, 90.97703119499891, 89.90649348270627, 89.43954474085717, 87.34140276866633, 362.1557445665134, 88.98103551989777, 81.93732709111454, 77.27899313611385, 74.49322675031094, 75.85413771064806, 73.1077088958535, 70.91951473998446, 69.17746406483913, 67.74540413138847, 399.46713214929196, 2208.8228427210483, 1794.4854439900175, 573.2924965623529, 116.33038266647105, 193.66477916526395, 293.3380009235853, 1043.6574111854416, 214.88070630327596, 15224.83594196445, 2559.8720475517366, 229.59594423409612, 920.2297058267644, 900.5570173327318, 235.77992159073298, 975.9163562577487, 830.9237283699296, 593.6781572568591, 219.55416002471796, 215.31431620399053, 182.64230359269396, 163.8921518139901, 144.50255149232825, 131.4757694765143, 132.56663328328807, 126.69673557798599, 125.16483854326482, 121.440422129577, 118.21522705936125, 112.24161930326319, 100.84331729652041, 95.16829392608392, 94.24742299781659, 85.16611209903498, 83.9139847886871, 83.54187058315551, 81.89477750220614, 81.38319192341739, 79.80804187774697, 72.822811693668, 72.14783716832419, 71.56253123189121, 68.00452973446762, 66.76365920489563, 65.48488113951038, 64.88312446206875, 161.73464275436282, 660.8576697140765, 458.5895986680089, 208.1850790982861, 209.46774184349383, 15224.83594196445, 143.5049031644346, 880.619834775665, 146.4131006167609], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.7922, -4.1979, -4.4183, -4.6108, -4.7594, -4.9504, -5.2585, -5.3044, -5.4131, -5.3046, -5.6422, -5.7362, -5.7638, -5.7842, -5.7985, -5.8174, -5.8464, -5.8465, -5.8861, -5.8894, -6.0052, -6.0453, -6.0496, -6.069, -6.0977, -6.0297, -5.0175, -6.0427, -6.2087, -6.2217, -5.9371, -4.0573, -4.7626, -5.1388, -5.4484, -4.7174, -4.7916, -4.5649, -4.5152, -5.4328, -4.5068, -4.7, -4.7632, -5.1975, -4.9236, -4.719, -5.1398, -5.5509, -4.537, -5.4915, -3.8855, -5.0882, -2.8451, -5.3969, -5.3532, -5.3874, -3.148, -4.4, -4.3964, -4.4882, -4.6598, -4.7715, -4.5489, -4.8836, -4.8843, -4.8849, -5.0143, -5.028, -5.1001, -4.9653, -5.2282, -5.2644, -5.285, -4.8768, -5.3527, -5.3586, -5.5116, -5.5269, -5.5782, -5.7195, -5.783, -5.8265, -5.8216, -5.8379, -5.8895, -5.9101, -4.2803, -3.6404, -5.4307, -4.5401, -4.5255, -4.3413, -3.9093, -3.9208, -4.7226, -5.0972, -4.8304, -4.0727, -3.9199, -4.9144, -3.9789, -4.5001, -3.1179, -5.0068, -4.9116, -2.7123, -2.7503, -2.7573, -4.453, -4.598, -4.823, -5.0868, -5.2869, -5.2964, -5.4783, -5.4573, -5.5835, -5.764, -5.827, -5.8287, -5.9495, -5.9578, -5.9673, -5.9947, -6.0044, -6.03, -6.0635, -6.0742, -6.1285, -6.1337, -6.1808, -6.2293, -6.2501, -6.2779, -6.313, -3.9799, -3.8838, -1.2338, -4.1016, -5.169, -5.0253, -5.7282, -4.5892, -4.1782, -5.2493, -5.8429, -5.8134, -5.6215, -5.6917, -5.9208, -3.9039, -4.3325, -4.4449, -4.4432, -4.9971, -5.0296, -5.0328, -5.2095, -5.2259, -5.2744, -5.37, -5.3713, -5.2818, -5.4649, -5.5139, -5.5286, -5.5455, -5.5574, -5.5627, -5.5866, -4.1647, -5.5684, -5.6512, -5.7103, -5.7473, -5.7292, -5.7663, -5.797, -5.8224, -5.8435, -4.2221, -2.735, -3.0992, -4.3655, -5.4502, -5.1138, -4.8521, -4.0634, -5.132, -2.9859, -3.9265, -5.1584, -4.9257, -5.1114, -5.3961, -5.3856, -3.0612, -3.3978, -4.3948, -4.4144, -4.5796, -4.6884, -4.815, -4.91, -4.9018, -4.9473, -4.9597, -4.9899, -5.0171, -5.0693, -5.1771, -5.2355, -5.2453, -5.3476, -5.3625, -5.3671, -5.3871, -5.3934, -5.4132, -5.5056, -5.515, -5.5234, -5.5751, -5.5935, -5.6132, -5.6227, -4.7221, -3.8255, -4.2718, -4.9072, -4.9621, -2.9249, -5.1988, -4.6889, -5.337], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8519, 0.8516, 0.8515, 0.8513, 0.8511, 0.8508, 0.8503, 0.8502, 0.85, 0.8499, 0.8493, 0.849, 0.8489, 0.8489, 0.8488, 0.8488, 0.8486, 0.8486, 0.8485, 0.8485, 0.848, 0.8479, 0.8479, 0.8478, 0.8476, 0.8475, 0.8473, 0.8472, 0.847, 0.847, 0.8465, 0.7924, 0.8022, 0.8168, 0.8232, 0.791, 0.7879, 0.7715, 0.7604, 0.8, 0.7058, 0.719, 0.7178, 0.7659, 0.7266, 0.6792, 0.7468, 0.8071, 0.5908, 0.793, 0.3628, 0.6648, -0.3798, 0.7527, 0.6729, 0.7227, 1.5519, 1.5506, 1.5506, 1.5505, 1.5501, 1.5499, 1.5498, 1.5496, 1.5496, 1.5496, 1.5492, 1.5491, 1.5489, 1.5488, 1.5484, 1.5483, 1.5482, 1.548, 1.5479, 1.5478, 1.5471, 1.547, 1.5468, 1.5459, 1.5455, 1.5452, 1.5452, 1.5451, 1.5448, 1.5446, 1.5383, 1.5155, 1.5395, 1.4904, 1.4749, 1.4338, 1.3837, 1.3505, 1.4489, 1.4617, 1.3907, 1.0728, 0.6835, 1.2574, 0.4169, 0.8153, -0.6527, 1.2697, 0.833, 2.0096, 2.0096, 2.0096, 2.0072, 2.0068, 2.0059, 2.0047, 2.0035, 2.0034, 2.0021, 2.0021, 2.001, 1.9994, 1.9986, 1.9984, 1.9973, 1.9972, 1.9971, 1.9967, 1.9964, 1.9962, 1.9957, 1.9956, 1.9947, 1.9946, 1.9938, 1.9932, 1.9928, 1.9926, 1.9919, 1.8281, 1.8144, 1.2314, 1.6195, 1.7848, 1.6305, 1.7597, 0.5386, 0.07, 1.1154, 1.3319, 1.1257, -0.3062, -0.842, 1.4068, 2.0469, 2.046, 2.0457, 2.0456, 2.0435, 2.0433, 2.0433, 2.0423, 2.0422, 2.0419, 2.0413, 2.0412, 2.0411, 2.0403, 2.0401, 2.04, 2.0399, 2.0397, 2.0397, 2.0395, 2.0392, 2.0391, 2.0387, 2.0382, 2.0379, 2.0379, 2.0377, 2.0374, 2.0369, 2.0367, 1.8837, 1.6607, 1.5043, 1.379, 1.8893, 1.716, 1.5625, 1.0821, 1.5939, -0.5206, 0.3217, 1.5012, 0.3456, 0.1815, 1.237, -0.173, 2.3122, 2.3119, 2.3095, 2.3095, 2.3088, 2.3083, 2.3077, 2.3071, 2.3071, 2.3068, 2.3066, 2.3066, 2.3064, 2.306, 2.3053, 2.3048, 2.3047, 2.3037, 2.3036, 2.3035, 2.3034, 2.3034, 2.3031, 2.3023, 2.3022, 2.302, 2.3013, 2.3012, 2.3009, 2.3007, 2.2878, 1.7769, 1.696, 1.8504, 1.7893, -0.4596, 1.9308, 0.6264, 1.7725]}, \"token.table\": {\"Topic\": [2, 2, 2, 2, 4, 2, 4, 3, 1, 2, 4, 4, 2, 4, 2, 3, 4, 3, 2, 3, 4, 1, 4, 1, 5, 5, 1, 1, 3, 1, 3, 2, 4, 5, 3, 1, 3, 3, 1, 3, 5, 5, 3, 1, 1, 1, 3, 4, 1, 5, 5, 1, 3, 4, 3, 1, 5, 1, 1, 2, 2, 1, 1, 2, 1, 1, 4, 5, 1, 2, 3, 4, 5, 3, 2, 4, 5, 4, 2, 4, 4, 3, 5, 2, 4, 4, 1, 3, 5, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4, 1, 2, 2, 4, 4, 2, 4, 2, 4, 2, 4, 3, 5, 1, 3, 1, 3, 5, 3, 3, 5, 1, 2, 4, 5, 1, 4, 5, 2, 5, 1, 5, 1, 3, 1, 3, 2, 4, 5, 4, 1, 3, 4, 2, 2, 4, 4, 4, 2, 3, 3, 2, 2, 4, 4, 3, 2, 2, 2, 4, 5, 5, 2, 4, 4, 4, 4, 1, 2, 2, 4, 1, 2, 4, 1, 5, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 5, 1, 2, 4, 1, 3, 5, 2, 4, 1, 1, 2, 5, 5, 1, 4, 1, 5, 1, 2, 5, 2, 2, 2, 1, 3, 1, 3, 4, 1, 5, 1, 2, 3, 4, 1, 2, 3, 1, 1, 5, 2, 1, 3, 2, 2, 4, 4, 2, 2, 4, 5, 3, 1, 3, 1, 5, 1, 2, 3, 5, 1, 1, 2, 1, 5, 1, 5, 4, 3, 5, 5, 3, 2, 5, 2, 3, 4, 3, 4, 5, 1, 2, 2, 4, 3, 1, 3, 4, 1, 4, 2, 4, 2, 2, 4, 1, 1, 5, 1, 1, 3, 1, 3, 3, 3, 5, 2, 4, 4, 1, 2, 5, 1, 3, 5, 2, 1, 4, 2, 2, 4], \"Freq\": [0.9995859329780721, 0.9947853313965538, 0.9948317667944693, 0.32143818248698985, 0.6786420218985885, 0.986345350884957, 0.011883678926324784, 0.9956667755393712, 0.9961442319320769, 0.48666257045569966, 0.5110829144929032, 0.9942541649538447, 0.9952843747214777, 0.0034438905699705107, 0.9897429430074223, 0.8007584679389644, 0.19872837890456052, 0.9770360648444416, 0.16542198874721403, 0.8326859658286729, 0.9945885993927169, 0.9220893654098818, 0.07655081524157509, 0.9968350330148048, 0.9925955253934511, 0.9935137844128574, 0.9944763781606085, 0.999458215216907, 0.9993952828592855, 0.5902248441951905, 0.4086171998274396, 0.7433354855935085, 0.2540175220553356, 0.984090484020384, 0.9884909804222127, 0.9977500390170622, 0.9850045890248712, 0.9884551380995041, 0.9516031500702173, 0.04809020513371696, 0.9988883114798734, 0.9877239164653795, 0.992876623927759, 0.9937850437450652, 0.9988605012334663, 0.996667937086063, 0.9863208793475706, 0.9921449881644769, 0.4057904059686131, 0.591976592236565, 0.9965221964101102, 0.9428259676011518, 0.02993098309844926, 0.026937884788604337, 0.978723682779594, 0.9493243949816652, 0.04831890633140212, 0.9969722498612065, 0.9567376420194559, 0.04187740520623881, 0.9923121151510231, 0.9957484698232009, 0.9721290615723486, 0.02659319621322534, 0.9968348836072038, 0.9049420017241607, 0.09415581520829418, 0.9985401983038938, 0.29169444038206044, 0.11028033447455066, 0.45898688344738536, 0.07658539011157002, 0.06246372726938516, 0.9825603523531028, 0.6189770638108523, 0.3803930252831399, 0.996381314379002, 0.9870343904162948, 0.996610184912283, 0.993378904743056, 0.982979080243018, 0.9898576561712099, 0.996373348166502, 0.3629921054425111, 0.632909312053609, 0.989485572271842, 0.9123716276549608, 0.06220715643102005, 0.02510113329672739, 0.9960911691609697, 0.940333448939352, 0.05804527462588593, 0.997865709956622, 0.9967063015938331, 0.9973666743000514, 0.9834496661484561, 0.9972875309899158, 0.008283728879106654, 0.9912862225330963, 0.9944327942867408, 0.9987038339165026, 0.9932631258141139, 0.845032558020511, 0.1543489166423798, 0.9889747796913603, 0.2788323216681494, 0.717735050219866, 0.9136535125302456, 0.08270139553075499, 0.817187268829122, 0.18256311324905916, 0.9907457805111308, 0.9897202154951575, 0.9952494806646875, 0.9897103044538513, 0.8285027585610539, 0.08267437293496716, 0.087951460569114, 0.9837163999482061, 0.9813838883829689, 0.9863889960696169, 0.9973884293549871, 0.5513616219860066, 0.4453305408348515, 0.9916373507027668, 0.8737600681934835, 0.1206110523579962, 0.004020368411933206, 0.9988494558584047, 0.9891080754776608, 0.4166293845498749, 0.5805491424055634, 0.770040502219546, 0.2296942329359037, 0.31238813412096356, 0.6855184054321144, 0.41961889550116005, 0.5801105846171416, 0.9906935641285377, 0.9906919333455411, 0.2989119483341871, 0.5103374727656853, 0.18955391845582595, 0.9969261630026689, 0.9009338945997779, 0.09624219645576262, 0.9974411052866452, 0.9987113920553358, 0.9894192707330057, 0.9931662825510731, 0.9759278008932833, 0.9968483483461577, 0.9980229670507904, 0.999069661336619, 0.9848482613860666, 0.9938645981478892, 0.9934686322333713, 0.9986513808006323, 0.9975861377352033, 0.9962654475530233, 0.9921393049937209, 0.998857702193403, 0.754151976281806, 0.24346638604373264, 0.9967868853981936, 0.991051169926161, 0.9950855659861562, 0.8367570197492322, 0.16180384359791783, 0.15020009200050113, 0.8486305198028314, 0.9992024750214181, 0.8884176656940358, 0.11150181229358344, 0.01854890176222975, 0.9769088261441002, 0.9996105570810946, 0.9892606828100957, 0.9887011820261872, 0.9914057985902145, 0.6129212596780346, 0.048439921096288266, 0.14375718518898453, 0.17774325886138032, 0.017188359098682934, 0.9162708455605988, 0.08033654333114255, 0.23733283279185058, 0.4780723569634885, 0.09879405001383254, 0.18509689830177822, 0.9376796379578816, 0.06211757853979657, 0.9942915390329953, 0.9938437196264023, 0.9939631089831936, 0.9867643808378136, 0.9947958641937398, 0.9925372635002659, 0.9972014236450701, 0.8754611149708857, 0.12344631549229755, 0.9863077922627375, 0.9945564701902099, 0.9407426684386798, 0.05922684442586125, 0.9989899944865593, 0.9974759757471433, 0.9007949661652093, 0.09852444942431976, 0.9957256719186856, 0.9974421874684233, 0.993864988197496, 0.9953102563840358, 0.9951685584868115, 0.9813129436331228, 0.5183867694838324, 0.4147094155870659, 0.06335838293691284, 0.9993069581072382, 0.9945007614063022, 0.12438454586086779, 0.09541828175628214, 0.6764474617365002, 0.10393777119880733, 0.17948269501189773, 0.039885043335977276, 0.7777583450515568, 0.9973863630731408, 0.9981245144057795, 0.985228487890587, 0.996771498026539, 0.45018894456414604, 0.5436243858887801, 0.9942766187365015, 0.8512052851291815, 0.1488906934384377, 0.9882058761062097, 0.9979051573276307, 0.06017344600395226, 0.8510244506273248, 0.0859620657199318, 0.995475908317054, 0.9953559671905878, 0.003934213309053707, 0.9924791003607504, 0.9890740590609451, 0.8773672048356843, 0.02011156916528789, 0.05279286905888072, 0.047764976767558746, 0.9965703187754968, 0.8825162817398099, 0.11745720296537038, 0.996005291353365, 0.00493071926412557, 0.9987012777142922, 0.995291510269369, 0.9887397347537422, 0.9977730543861637, 0.9898751822656574, 0.996483270414031, 0.9923879624305421, 0.3135781357131533, 0.6829034955530895, 0.176519173491792, 0.8226459594806155, 0.9885604385157423, 0.9993643296315713, 0.9889969786003078, 0.9885617532952772, 0.8413266917730918, 0.15790295681371813, 0.3818121063325036, 0.6136265994629523, 0.9796114676452218, 0.863803536639728, 0.02766630544397705, 0.10861586581709509, 0.9651046579012583, 0.03446802349647351, 0.41812585287708026, 0.5792785253401216, 0.997185792643337, 0.9862273432208216, 0.013149697909610956, 0.9987073675046672, 0.414612726093574, 0.5856026459788801, 0.9993029796754883, 0.9993815814202092, 0.9907016495186602, 0.941729694872519, 0.05774421293313704, 0.9886491111996455, 0.990248157469065, 0.9889379776328022, 0.9259721222967323, 0.07209515307419813, 0.9899173747346666, 0.40341080682453245, 0.056695572851015376, 0.538607942084646, 0.32663243828294036, 0.04323076389038917, 0.6292477855156645, 0.9919334544821844, 0.9967972607460219, 0.9892400713220251, 0.9954446498061149, 0.9633880670566416, 0.035824480885523355], \"Term\": [\"ako\", \"akong\", \"alam\", \"ang\", \"ang\", \"anong\", \"anong\", \"asking\", \"assault\", \"babae\", \"babae\", \"bahay\", \"bakit\", \"bakit\", \"bastos\", \"beast\", \"beast\", \"beasts\", \"ben\", \"ben\", \"biktima\", \"blaming\", \"blaming\", \"body\", \"came\", \"cases\", \"catcalled\", \"clothes\", \"com\", \"consent\", \"consent\", \"dahil\", \"dahil\", \"darssthsdobetter\", \"decent\", \"did\", \"doesn\", \"doing\", \"dont\", \"dont\", \"dress\", \"dressed\", \"endrapeculture\", \"exists\", \"fault\", \"feel\", \"finally\", \"frankie\", \"friend\", \"friend\", \"girl\", \"girls\", \"girls\", \"girls\", \"god\", \"got\", \"got\", \"groped\", \"guy\", \"guy\", \"habang\", \"hand\", \"happened\", \"happened\", \"harassed\", \"harassment\", \"harassment\", \"hija\", \"hijaako\", \"hijaako\", \"hijaako\", \"hijaako\", \"hijaako\", \"hijoako\", \"hindi\", \"hindi\", \"house\", \"huwag\", \"iba\", \"iisip\", \"ilang\", \"ill\", \"instead\", \"isang\", \"isang\", \"ito\", \"just\", \"just\", \"just\", \"kababaihan\", \"kahit\", \"kahit\", \"kami\", \"kasalanan\", \"kasi\", \"kay\", \"kaya\", \"kayo\", \"kayo\", \"kayong\", \"know\", \"kong\", \"kung\", \"kung\", \"ladies\", \"lahat\", \"lahat\", \"lalaki\", \"lalaki\", \"lang\", \"lang\", \"leave\", \"legs\", \"let\", \"lets\", \"like\", \"like\", \"like\", \"literally\", \"lives\", \"lol\", \"long\", \"mag\", \"mag\", \"making\", \"man\", \"man\", \"man\", \"manyak\", \"maybe\", \"mean\", \"mean\", \"men\", \"men\", \"metoo\", \"metoo\", \"mga\", \"mga\", \"molested\", \"mong\", \"movement\", \"movement\", \"movement\", \"naka\", \"naman\", \"naman\", \"nang\", \"nasa\", \"natin\", \"navarro\", \"new\", \"nila\", \"niya\", \"niyo\", \"niyong\", \"normal\", \"nun\", \"nung\", \"nya\", \"nyo\", \"offenders\", \"old\", \"pag\", \"pag\", \"pananamit\", \"pang\", \"pangilinan\", \"pants\", \"pants\", \"para\", \"para\", \"people\", \"pero\", \"pero\", \"person\", \"person\", \"pic\", \"problema\", \"protectourstudents\", \"proud\", \"rape\", \"rape\", \"rape\", \"rape\", \"rape\", \"raped\", \"raped\", \"rapist\", \"rapist\", \"rapist\", \"rapist\", \"rapists\", \"rapists\", \"rhymeswithwrong\", \"right\", \"rights\", \"room\", \"sakin\", \"sana\", \"say\", \"school\", \"school\", \"self\", \"sex\", \"sexual\", \"sexual\", \"sexually\", \"sexy\", \"shirt\", \"shirt\", \"short\", \"sila\", \"siya\", \"sobrang\", \"speak\", \"stan\", \"stand\", \"stand\", \"stand\", \"stop\", \"stoprapingwomen\", \"stopvictimblaming\", \"stopvictimblaming\", \"stopvictimblaming\", \"stopvictimblaming\", \"stopvictimshaming\", \"stopvictimshaming\", \"stopvictimshaming\", \"stories\", \"story\", \"stupid\", \"suot\", \"support\", \"support\", \"sya\", \"talaga\", \"talaga\", \"taong\", \"tapos\", \"tayo\", \"tayo\", \"tayo\", \"teach\", \"tell\", \"tell\", \"telling\", \"theres\", \"think\", \"think\", \"think\", \"think\", \"thinking\", \"time\", \"time\", \"times\", \"times\", \"touched\", \"touching\", \"toxic\", \"trash\", \"trending\", \"tried\", \"try\", \"tshirt\", \"tshirt\", \"tulfo\", \"tulfo\", \"tweet\", \"twitter\", \"ulit\", \"uncle\", \"uniform\", \"uniform\", \"utak\", \"utak\", \"vhong\", \"victim\", \"victim\", \"victim\", \"victims\", \"victims\", \"wag\", \"wag\", \"wala\", \"walang\", \"walang\", \"want\", \"way\", \"way\", \"wear\", \"wearing\", \"wears\", \"women\", \"women\", \"words\", \"world\", \"yall\", \"yan\", \"yan\", \"yang\", \"years\", \"years\", \"years\", \"yes\", \"yes\", \"yes\", \"yon\", \"youre\", \"yrs\", \"yun\", \"yung\", \"yung\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 4, 2, 3, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2987629542070888407553297465\", ldavis_el2987629542070888407553297465_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2987629542070888407553297465\", ldavis_el2987629542070888407553297465_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2987629542070888407553297465\", ldavis_el2987629542070888407553297465_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=                x           y  topics  cluster       Freq\n",
       "topic                                                    \n",
       "0      150.222153  -72.269554       1        1  42.641849\n",
       "3       51.163364 -159.968018       2        1  21.174904\n",
       "1      -73.144554   21.523815       3        1  13.397385\n",
       "2      -66.410133 -110.606438       4        1  12.891475\n",
       "4       54.417324   12.443444       5        1   9.894386, topic_info=         Term          Freq         Total Category  logprob  loglift\n",
       "1649  hijaako  15224.000000  15224.000000  Default  30.0000  30.0000\n",
       "4660  twitter   1594.000000   1594.000000  Default  29.0000  29.0000\n",
       "135       ang   2208.000000   2208.000000  Default  28.0000  28.0000\n",
       "3304      pic   1534.000000   1534.000000  Default  27.0000  27.0000\n",
       "688       com   1523.000000   1523.000000  Default  26.0000  26.0000\n",
       "...       ...           ...           ...      ...      ...      ...\n",
       "1346   friend    124.046892    209.467742   Topic5  -4.9621   1.7893\n",
       "1649  hijaako    951.324958  15224.835942   Topic5  -2.9249  -0.4596\n",
       "4622   tshirt     97.903992    143.504903   Topic5  -5.1988   1.9308\n",
       "3592   rapist    163.019759    880.619835   Topic5  -4.6889   0.6264\n",
       "2636     mean     85.260503    146.413101   Topic5  -5.3370   1.7725\n",
       "\n",
       "[265 rows x 6 columns], token_table=      Topic      Freq   Term\n",
       "term                        \n",
       "100       2  0.999586    ako\n",
       "101       2  0.994785  akong\n",
       "105       2  0.994832   alam\n",
       "135       2  0.321438    ang\n",
       "135       4  0.678642    ang\n",
       "...     ...       ...    ...\n",
       "4989      1  0.996797  youre\n",
       "4994      4  0.989240    yrs\n",
       "4996      2  0.995445    yun\n",
       "4997      2  0.963388   yung\n",
       "4997      4  0.035824   yung\n",
       "\n",
       "[312 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 4, 2, 3, 5])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Log Likelyhoods from Grid Search Output\n",
    "n_topics = [10, 15, 20, 25, 30]\n",
    "log_likelyhoods_5 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.5]\n",
    "log_likelyhoods_7 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.7]\n",
    "log_likelyhoods_9 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.9]\n",
    "\n",
    "# Show graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(n_topics, log_likelyhoods_5, label='0.5')\n",
    "plt.plot(n_topics, log_likelyhoods_7, label='0.7')\n",
    "plt.plot(n_topics, log_likelyhoods_9, label='0.9')\n",
    "plt.title(\"Choosing Optimal LDA Model\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Log Likelyhood Scores\")\n",
    "plt.legend(title='Learning decay', loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = best_lda_model.transform(data_vectorized)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_topics)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution = df_document_topic['dominant_topic'].value_counts().reset_index(name=\"Num Documents\")\n",
    "df_topic_distribution.columns = ['Topic Num', 'Num Documents']\n",
    "df_topic_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "panel = pyLDAvis.sklearn.prepare(best_lda_model, data_vectorized, vectorizer, mds='tsne')\n",
    "panel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialAnalysis",
   "language": "python",
   "name": "socialanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
